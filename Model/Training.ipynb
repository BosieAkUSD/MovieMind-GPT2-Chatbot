{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7jf-pBb9MCr",
        "outputId": "0677d0c6-d8f5-4662-f57f-94394cc69ec5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.14.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5DDeIj1vB7v",
        "outputId": "1c7e9ac4-0e0c-421a-dbde-1956dc0d585f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_ids': [568, 545, 407, 1016, 284, 1487, 534, 12046, 319, 262, 826, 780, 345, 260, 5543, 3376, 262, 826, 389, 32627, 16196, 290, 22388, 1128, 34718, 2592, 618, 2045, 379, 262, 31082, 1312, 765, 284, 11508, 345, 326, 428, 318, 2081, 286, 1111, 5389, 329, 262, 6573, 7515, 262, 1364, 468, 7953, 287, 7619, 870, 661, 4395, 661, 3503, 612, 743, 407, 307, 867, 7040, 475, 407, 422, 3092, 286, 2111, 611, 428, 318, 588, 15774, 661, 319, 17044, 290, 256, 15566, 1312, 17666, 18869, 766, 534, 17044, 393, 256, 15566, 21318, 355, 329, 262, 5654, 7515, 257, 1256, 286, 7272, 50256, 5562, 11543, 4519, 318, 12361, 475, 703, 318, 326, 5884, 284, 262, 1364, 698, 76, 373, 429, 2950, 262, 4395, 286, 1644, 3790, 373, 257, 13574, 475, 262, 30091, 2950, 14005, 287, 7208, 284, 644, 262, 3146, 286, 24270, 15102, 852, 2823, 416, 1644, 423, 1716, 355, 329, 1034, 11392, 345, 24628, 607, 329, 33064, 4234, 9056, 475, 19997, 318, 852, 33064, 4234, 826, 783, 290, 339, 373, 7018, 1893, 1034, 11392, 318, 407, 772, 319, 262, 11100, 1865, 24628, 428, 618, 673, 7864, 262, 10518, 4165, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [568, 545, 407, 1016, 284, 1487, 534, 12046, 319, 262, 826, 780, 345, 260, 5543, 3376, 262, 826, 389, 32627, 16196, 290, 22388, 1128, 34718, 2592, 618, 2045, 379, 262, 31082, 1312, 765, 284, 11508, 345, 326, 428, 318, 2081, 286, 1111, 5389, 329, 262, 6573, 7515, 262, 1364, 468, 7953, 287, 7619, 870, 661, 4395, 661, 3503, 612, 743, 407, 307, 867, 7040, 475, 407, 422, 3092, 286, 2111, 611, 428, 318, 588, 15774, 661, 319, 17044, 290, 256, 15566, 1312, 17666, 18869, 766, 534, 17044, 393, 256, 15566, 21318, 355, 329, 262, 5654, 7515, 257, 1256, 286, 7272, 50256, 5562, 11543, 4519, 318, 12361, 475, 703, 318, 326, 5884, 284, 262, 1364, 698, 76, 373, 429, 2950, 262, 4395, 286, 1644, 3790, 373, 257, 13574, 475, 262, 30091, 2950, 14005, 287, 7208, 284, 644, 262, 3146, 286, 24270, 15102, 852, 2823, 416, 1644, 423, 1716, 355, 329, 1034, 11392, 345, 24628, 607, 329, 33064, 4234, 9056, 475, 19997, 318, 852, 33064, 4234, 826, 783, 290, 339, 373, 7018, 1893, 1034, 11392, 318, 407, 772, 319, 262, 11100, 1865, 24628, 428, 618, 673, 7864, 262, 10518, 4165, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from datasets import Dataset\n",
        "from transformers import Trainer, TrainingArguments, GPT2Tokenizer, AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# Load dataset\n",
        "with open(\"preprocessed_data.json\", \"r\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "\n",
        "\n",
        "# Initially load the \"gpt2-medium\" model to cross train\n",
        "# Load previously trained weights from ./gpt2-finetuned-movie-dialog To resume training\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2-medium\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"gpt2-medium\")\n",
        "\n",
        "# Prepare the dataset in the correct format\n",
        "formatted_data = []\n",
        "for conversation in data:\n",
        "    input_ids = conversation[0]\n",
        "    response_ids = conversation[1]\n",
        "\n",
        "    # Concatenate input and response with a separator (if needed)\n",
        "    combined_ids = input_ids + [tokenizer.eos_token_id] + response_ids\n",
        "\n",
        "    formatted_data.append({\n",
        "        \"input_ids\": combined_ids,\n",
        "        \"attention_mask\": [1] * len(combined_ids),\n",
        "        \"labels\": combined_ids  # Labels are the same as input_ids (GPT-2 copies the input)\n",
        "    })\n",
        "\n",
        "# Convert to a Huggingface Dataset\n",
        "dataset = Dataset.from_list(formatted_data)\n",
        "# Load your dataset and split it\n",
        "dataset_split = dataset.train_test_split(test_size=0.05)  # 95% train, 5% validation\n",
        "\n",
        "# Separate the train and validation datasets\n",
        "train_dataset = dataset_split[\"train\"]\n",
        "val_dataset = dataset_split[\"test\"]\n",
        "print(train_dataset[0])  # Verify the format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QgIWiqm6vHqt",
        "outputId": "c2b95e8a-4d0c-47ef-a899-e7b1674b4671"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2258' max='2258' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2258/2258 42:08, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>2.386100</td>\n",
              "      <td>2.182600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>2.222800</td>\n",
              "      <td>2.099441</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>2.158500</td>\n",
              "      <td>2.046740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>2.136600</td>\n",
              "      <td>2.012127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>2.106300</td>\n",
              "      <td>1.982360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>2.092800</td>\n",
              "      <td>1.964738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>2.079700</td>\n",
              "      <td>1.955730</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0 saved to drive\n",
            "You are a friendly chatbot specializing in movie dialog. \n",
            "User: What's your favorite movie? \n",
            "ChatBot: ive watched a few i think there are some movies that i would definitely feel good about watching but youve already answered this question your choices are pretty obvious anyway gt i thought the movie was about a man who has a difficult time getting past his mental issues by having the support of his wife and kid gtbut it ends up seeming like a pretty shallow movie especially\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2258' max='2258' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2258/2258 42:05, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.982400</td>\n",
              "      <td>1.940645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>1.942900</td>\n",
              "      <td>1.908252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>1.927400</td>\n",
              "      <td>1.878151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>1.943900</td>\n",
              "      <td>1.854815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>1.947600</td>\n",
              "      <td>1.836862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>1.961800</td>\n",
              "      <td>1.824348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>1.974300</td>\n",
              "      <td>1.817998</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1 saved to drive\n",
            "You are a friendly chatbot specializing in movie dialog. \n",
            "User: What's your favorite movie? \n",
            "ChatBot: ive watched a lot i think there are some movies that i would definitely feel very comfortable with seeing when i am not a big movie fan but none of them would feel the same with my wife over!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2258' max='2258' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2258/2258 42:14, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.739700</td>\n",
              "      <td>1.820507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>1.725800</td>\n",
              "      <td>1.800269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>1.737800</td>\n",
              "      <td>1.769617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>1.784700</td>\n",
              "      <td>1.747262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>1.818800</td>\n",
              "      <td>1.729788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>1.862900</td>\n",
              "      <td>1.719302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>1.903000</td>\n",
              "      <td>1.715846</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 2 saved to drive\n",
            "You are a friendly chatbot specializing in movie dialog. \n",
            "User: What's your favorite movie? \n",
            "ChatBot: ive watched a lot i think there are some movies that i would personally feel very uncomfortable with seeing when i am not a fan of the subject matter also i dont think the same could be said for most of the medium nowadays people are too busy talking to look for any sort of entertainment while consuming the entertainment that they are consuming this is not a big problem in the digital\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2258' max='2258' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2258/2258 42:12, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.485500</td>\n",
              "      <td>1.746999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>1.498400</td>\n",
              "      <td>1.742814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>1.542700</td>\n",
              "      <td>1.697344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>1.626900</td>\n",
              "      <td>1.668061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>1.697800</td>\n",
              "      <td>1.646585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>1.777200</td>\n",
              "      <td>1.636982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>1.848300</td>\n",
              "      <td>1.637164</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 3 saved to drive\n",
            "You are a friendly chatbot specializing in movie dialog. \n",
            "User: What's your favorite movie? \n",
            "ChatBot: ive never been a big movie fiend and i wasnt raised to do so movies with strong female leads and female characters that arent forced to be relatable to the same amount as white men!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1885' max='2258' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1885/2258 35:13 < 06:58, 0.89 it/s, Epoch 0.83/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.221800</td>\n",
              "      <td>1.731229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>1.264800</td>\n",
              "      <td>1.742235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>1.339000</td>\n",
              "      <td>1.671264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>1.463100</td>\n",
              "      <td>1.618021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>1.577400</td>\n",
              "      <td>1.584759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>1.697800</td>\n",
              "      <td>1.572832</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import shutil\n",
        "from google.colab import drive\n",
        "from transformers import pipeline\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "for epoch in range(10):\n",
        "  training_args = TrainingArguments(\n",
        "    output_dir=\"./gpt2-finetuned\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=32,  # Further reduced batch size if needed\n",
        "    save_steps=300,\n",
        "    save_total_limit=2,\n",
        "    logging_dir=\"./logs\",\n",
        "    eval_strategy=\"steps\",  # Evaluate every 'eval_steps'\n",
        "    eval_steps=300,  # Evaluate every __ steps\n",
        "    logging_steps=300,  # Log training and validation loss every __ steps\n",
        "  )\n",
        "\n",
        "  # Initialize the Trainer with train and validation datasets\n",
        "  trainer = Trainer(\n",
        "      model=model,\n",
        "      args=training_args,\n",
        "      train_dataset=dataset,  # Training dataset\n",
        "      eval_dataset=val_dataset,  # Validation dataset\n",
        "  )\n",
        "\n",
        "  # Start training\n",
        "  trainer.train()\n",
        "\n",
        "  model.save_pretrained(\"./gpt2-finetuned-movie-dialog\")\n",
        "  tokenizer.save_pretrained(\"./gpt2-finetuned-movie-dialog\")\n",
        "\n",
        "  # Zip the directory\n",
        "  shutil.make_archive(f'gpt2-finetuned-movie-dialog', 'zip', './gpt2-finetuned-movie-dialog')\n",
        "  !cp -r ./gpt2-finetuned-movie-dialog.zip /content/drive/MyDrive/\n",
        "  print(f\"Epoch: {epoch} saved to drive\" )\n",
        "  epoch += 1\n",
        "\n",
        "  # Load fine-tuned model\n",
        "  generator = pipeline(\"text-generation\", model=\"./gpt2-finetuned-movie-dialog\", tokenizer=tokenizer)\n",
        "\n",
        "  # Test the model\n",
        "  response = generator(\n",
        "      \"You are a friendly chatbot specializing in movie dialog. \\nUser: What's your favorite movie? \\nChatBot: \",\n",
        "      max_length=200,\n",
        "      num_return_sequences=1,\n",
        "      min_new_tokens = 5\n",
        "  )\n",
        "  print(response[0]['generated_text'])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}